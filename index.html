<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
<!--   <title>Perfect Attribution and Enhanced Factuality</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico"> -->
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Perfect Attribution and Enhanced Factuality</h1>
<!--             <div class="is-size-5 publication-authors"> -->
              <!-- Paper authors -->
<!--               <span class="author-block">
                <a href="FIRST AUTHOR PERSONAL LINK" target="_blank">First Author</a><sup>*</sup>,</span>
                <span class="author-block">
                  <a href="SECOND AUTHOR PERSONAL LINK" target="_blank">Second Author</a><sup>*</sup>,</span>
                  <span class="author-block">
                    <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Third Author</a>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">Institution Name<br>Conferance name and year</span>
                    <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links"> -->
                         <!-- Arxiv PDF link -->
<!--                       <span class="link-block">
                        <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span> -->

                    <!-- Supplementary PDF link -->
<!--                     <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span> -->

                  <!-- Github link -->
<!--                   <span class="link-block">
                    <a href="https://github.com/YOUR REPO HERE" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
 -->
                <!-- ArXiv abstract Link -->
<!--                 <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
<!--             </div> -->
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%"> -->
        <!-- Your video here -->
<!--         <source src="static/videos/banner_video.mp4"
        type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        Aliquam vitae elit ullamcorper tellus egestas pellentesque. Ut lacus tellus, maximus vel lectus at, placerat pretium mi. Maecenas dignissim tincidunt vestibulum. Sed consequat hendrerit nisl ut maximus. 
      </h2>
    </div>
  </div>
</section> -->
<!-- End teaser video -->

<!-- Paper abstract -->
<!-- <section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Lorem ipsum dolor sit amet, consectetur adipiscing elit. Proin ullamcorper tellus sed ante aliquam tempus. Etiam porttitor urna feugiat nibh elementum, et tempor dolor mattis. Donec accumsan enim augue, a vulputate nisi sodales sit amet. Proin bibendum ex eget mauris cursus euismod nec et nibh. Maecenas ac gravida ante, nec cursus dui. Vivamus purus nibh, placerat ac purus eget, sagittis vestibulum metus. Sed vestibulum bibendum lectus gravida commodo. Pellentesque auctor leo vitae sagittis suscipit.
          </p>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End paper abstract -->

  <!-- Paper abstract -->
<section class="section hero small">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <div class="content has-text-justified">
          <p>
            Since we cannot exactly train large language models (LLM) every time we get new data, we need a way to provide it with new information without re-training the model. One way of doing this is to include that new information in the prompt of the model and tell the model to use that information to answer the question in the prompt. This is what we call RAG – Retrieval Augmented Generation – where we retrieve documents add them to the prompt and give an instruction to use them as context for the answer. However, would you stake your life on the LLM only using the information provided in the documents?
          </p>
          <p>
            I bet you and most of the people reading this article answered “No” to that question. If you’ve used any LLMs before, you probably know about their tendency to confidently state false facts or talk about some random topic not related to your question, even the best models are not immune to this behavior. In this blog, I will talk about ways to combat this problem. More specifically, I will show a method that guarantees attribution of the exact text used to generate an answer and also evaluates its own answer, so you can better decide whether to trust the answer or not.
          </p>
          <img src="static/images/hallucination_example.png" alt="Examples of Hallucination" class="blend-img-background center-image">
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section hero small">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <div class="content has-text-justified">
          <p>
            Now, let’s define attribution more formally. In short, it refers to the capacity of a model to provide evidence as references or citations of the statements it produces. The primary purpose of attribution is enabling users to validate the claims made by the model. The standard way of retrieving and citing references is to assign each reference a number, combine them all in the prompt, and instruct the model to cite them by appending their respective number after using them. However, this method has some drawbacks:
          </p>
          <img src="static/images/standard_rag.png" alt="Standard RAG" class="blend-img-background center-image">
        </div>
      </div>
    </div>
  </div>
</section>
  
<section class="section hero small">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <div class="content has-text-justified">
          <p>
            As you can observe in the figure above, standard RAG has two problems. One is that it includes all documents retrieved even if those documents are irrelevant. The other problem is that its citations are not accurate or precise. A popular way of dealing with this problem is to instruct-tune models along with retrieved documents, and research has shown that this method is effective at increasing the performance of the model. Having said that, for the same reason we cannot trust LLMs to always give us the right answer, we cannot trust them to always cite references correctly. Even if they do it correctly more often, they will make a mistake sooner or later. Hence, I will introduce a framework called Self-Reflective Retrieval-Augmented Gen- eration (SELF-RAG) that doesn’t rely on the model to cite references. Instead, it generates a different answer for each reference, and at the end, it selects the best answer. Since each answer only uses one reference, we won’t have to guess which reference the model used to answer the question. If the question couldn’t be answer using one source, it would keep repeating this process until its answer is complete. 
          </p>
          <img src="static/images/self_rag.png" alt="SELF-RAG" class="blend-img-background center-image">
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section hero small">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <div class="content has-text-justified">
          <p>
            The most important part of this framework is the generation of reflection tokens which are used to rank and select the answers. Without them, the model cannot reliably compare the generated texts, and simply comparing the overall probability of the text doesn’t help much.
          </p>
          <img src="static/images/other_llms.png" alt="Without Reflection Tokens" class="blend-img-background center-image">
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section hero small">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <div class="content has-text-justified">
          <p>
            Since reflection tokens are the heart of SELF-RAG, let’s discuss them in more detail. There are a total of four tokens. The first token the SELF-RAG predicts is the retrieve token to decide whether the question requires information from external documents or not. The main purpose of this token is to maximize the creativity on the when the task doesn’t external knowledge to answer the question. Some examples of this type of task are writing a story, performing a mathematical operation, or using logic to answer. In these cases, including documents in the prompt will probably hurt the fluency of the answer. The other three tokens predict the relevancy of the document to the question, the amount of support the document provides the answer, and the level of usefulness of the answer to the question. The framework uses these three tokens to score and rank the answers. They can also be used to filter undesirable predictions, such as the ones generated using an irrelevant document or the ones not supported by its document.
          </p>
          <img src="static/images/reflection_tokens.png" alt="Standard RAG" class="blend-img-background center-image">
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section hero small">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <div class="content has-text-justified">
          <p>
            As for how exactly the score is calculated, it basically combines the probabilities of all three tokens to create something akin to a confidence score of the answer. Since the score is based on the probabilities of the tokens, most if not all answers will have a different score even if their reflection tokens are the same. In my experience, this method provides a fairly accurate assessment of the generation because the probabilities of these tokens tend to be higher when the model knows the answer, and they are usually lower when the model is unsure or hallucinates. Also, this score does not have a high correlation with the overall probability of the generated tokens. During my experiments, I found that the overall probability of the generated tokens wasn’t an accurate indicator of the quality of answer, and it led to a much lower performance.         
          </p>
          <img src="static/images/score_calculation.png" alt="Reflection Score Calculation" class="blend-img-background center-image" width="600">
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section hero small">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <div class="content has-text-justified">
          <p>
            Below is a table comparing its accuracy with the following models:

            <ul>
              <li>No Retrieval Models
                <ul>
                  <li>Llama2 7B, 13B</li>
                  <li>Alpaca 7B, 13B: An instruction-tuned model</li>
                  <li>CoVE65B: Iteratively prompts Llama2 65B to refine output</li>
                </ul>
              </li>
              <li>Standard RAG Models
                <ul>
                  <li>Llama2 7B, 13B</li>
                  <li>Alpaca 7B, 13B: An instruction-tuned model</li>
                  <li>Llama2-FT: Fine-3tuned on all training data they use without the reflection tokens or retrieved passages</li>
                  <li>Ret-ChatGPT: ChatGPT with retrieval</li>
                  <li>Ret-Llama2-chat: Llama2-chat with retrieval</li>
                </ul>
              </li>
              <li>Models Instruct-tuned with Retrieved Text
                <ul>
                  <li>SAIL instruction-tune an LM on the Alpaca with retrieved examples</li>
                  <li>Toolformer pre-trained to do API calls and use returned text</li>
                </ul>
              </li>
            </ul>
          </p>
          <img src="static/images/results.png" alt="Results" class="blend-img-background center-image">
        </div>
      </div>
    </div>
  </div>
</section>


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>
      @misc{asai2023selfrag,
      title={Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection}, 
      author={Akari Asai and Zeqiu Wu and Yizhong Wang and Avirup Sil and Hannaneh Hajishirzi},
      year={2023},
      eprint={2310.11511},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
      }
      </code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
